This file is automatically generated by assertExpectedJournal calls in test_loops.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestLoops.test_3d_device_loop0)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime.triton_helpers import math as tl_math
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_device_loop_3d(x, out, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0
    indices_0 = offset_0 + tl.zeros([1], tl.int32)
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    for offset_1 in tl.range(0, 128, _BLOCK_SIZE_1):
        indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        for offset_2 in tl.range(0, 128, _BLOCK_SIZE_2):
            indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
            for offset_3 in tl.range(0, 128, _BLOCK_SIZE_3):
                indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
                # src[test_loops.py:N]: x[tile_a, tile_b, tile_c, tile_d]
                load = tl.load(x + (indices_0[:, None, None, None] * 2097152 + indices_1[None, :, None, None] * 16384 + indices_2[None, None, :, None] * 128 + indices_3[None, None, None, :] * 1), None)
                # src[test_loops.py:N]: out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
                # src[test_loops.py:N]:     x[tile_a, tile_b, tile_c, tile_d]
                # src[test_loops.py:N]: )
                v_0 = tl_math.sin(load)
                tl.store(out + (indices_0[:, None, None, None] * 2097152 + indices_1[None, :, None, None] * 16384 + indices_2[None, None, :, None] * 128 + indices_3[None, None, None, :] * 1), v_0, None)

def device_loop_3d(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: a, b, c, d = x.shape
    a, b, c, d = x.shape
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_3 = 8
    _BLOCK_SIZE_2 = 8
    _BLOCK_SIZE_1 = 8
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    # src[test_loops.py:N]:     for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:         out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_device_loop_3d, (128,), x, out, _BLOCK_SIZE_3, _BLOCK_SIZE_2, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_3d_device_loop1)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime.triton_helpers import math as tl_math
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_device_loop_3d(x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    for offset_2 in tl.range(0, 128, _BLOCK_SIZE_2):
        indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
        for offset_1 in tl.range(0, 128, _BLOCK_SIZE_1):
            indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
            for offset_3 in tl.range(0, 128):
                indices_3 = offset_3 + tl.arange(0, 1).to(tl.int32)
                # src[test_loops.py:N]: x[tile_a, tile_b, tile_c, tile_d]
                load = tl.load(x + (indices_0[:, None, None, None] * 2097152 + indices_1[None, :, None, None] * 16384 + indices_2[None, None, :, None] * 128 + indices_3[None, None, None, :] * 1), None)
                # src[test_loops.py:N]: out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
                # src[test_loops.py:N]:     x[tile_a, tile_b, tile_c, tile_d]
                # src[test_loops.py:N]: )
                v_0 = tl_math.sin(load)
                tl.store(out + (indices_0[:, None, None, None] * 2097152 + indices_1[None, :, None, None] * 16384 + indices_2[None, None, :, None] * 128 + indices_3[None, None, None, :] * 1), v_0, None)

def device_loop_3d(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: a, b, c, d = x.shape
    a, b, c, d = x.shape
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    _BLOCK_SIZE_0 = 2
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_1 = 8
    _BLOCK_SIZE_2 = 4
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    # src[test_loops.py:N]:     for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:         out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_device_loop_3d, (triton.cdiv(128, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_3d_device_loop2)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime.triton_helpers import math as tl_math
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_device_loop_3d(x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1_2_3: tl.constexpr):
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    for lid_1_2_3 in tl.range(tl.cdiv(2097152, _BLOCK_SIZE_1_2_3)):
        offsets_1_2_3 = lid_1_2_3 * _BLOCK_SIZE_1_2_3 + tl.arange(0, _BLOCK_SIZE_1_2_3).to(tl.int32)
        indices_2 = offsets_1_2_3 % 128
        indices_1 = offsets_1_2_3 // 128 % 128
        indices_3 = offsets_1_2_3 // 16384
        # src[test_loops.py:N]: x[tile_a, tile_b, tile_c, tile_d]
        load = tl.load(x + (indices_0[:, None] * 2097152 + indices_1[None, :] * 16384 + indices_2[None, :] * 128 + indices_3[None, :] * 1), None)
        # src[test_loops.py:N]: out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
        # src[test_loops.py:N]:     x[tile_a, tile_b, tile_c, tile_d]
        # src[test_loops.py:N]: )
        v_0 = tl_math.sin(load)
        tl.store(out + (indices_0[:, None] * 2097152 + indices_1[None, :] * 16384 + indices_2[None, :] * 128 + indices_3[None, :] * 1), v_0, None)

def device_loop_3d(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: a, b, c, d = x.shape
    a, b, c, d = x.shape
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    _BLOCK_SIZE_0 = 4
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_1_2_3 = 128
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    # src[test_loops.py:N]:     for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:         out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_device_loop_3d, (triton.cdiv(128, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1_2_3, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_3d_device_loop3)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime.triton_helpers import math as tl_math
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_device_loop_3d(x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    for offset_3 in tl.range(0, 128):
        for offset_1 in tl.range(0, 128, _BLOCK_SIZE_1):
            for offset_2 in tl.range(0, 128, _BLOCK_SIZE_2):
                # src[test_loops.py:N]: x[tile_a, tile_b, tile_c, tile_d]
                load = tl.load(tl.make_block_ptr(x, [128, 128, 128, 128], [2097152, 16384, 128, 1], [offset_0, offset_1, offset_2, offset_3], [_BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3], [3, 2, 1, 0]), boundary_check=[0, 1, 2, 3], padding_option='zero')
                # src[test_loops.py:N]: out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
                # src[test_loops.py:N]:     x[tile_a, tile_b, tile_c, tile_d]
                # src[test_loops.py:N]: )
                v_0 = tl_math.sin(load)
                tl.store(tl.make_block_ptr(out, [128, 128, 128, 128], [2097152, 16384, 128, 1], [offset_0, offset_1, offset_2, offset_3], [_BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3], [3, 2, 1, 0]), v_0, boundary_check=[0, 1, 2, 3])

def device_loop_3d(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: a, b, c, d = x.shape
    a, b, c, d = x.shape
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    _BLOCK_SIZE_0 = 2
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_2 = 4
    _BLOCK_SIZE_1 = 8
    # src[test_loops.py:N]: x[tile_a, tile_b, tile_c, tile_d]
    _BLOCK_SIZE_3 = 1
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    # src[test_loops.py:N]:     for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:         out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_device_loop_3d, (triton.cdiv(128, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_2, _BLOCK_SIZE_1, _BLOCK_SIZE_3, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_chebyshev_polynomials)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_chebyshev_kernel(x, w, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    num_blocks_0 = tl.cdiv(123, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < 123
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    # src[test_loops.py:N]: in_x = x[b_tile, c_tile]
    in_x = tl.load(x + (indices_0[:, None] * 64 + indices_1[None, :] * 1), mask_0[:, None], other=0)
    # src[test_loops.py:N]: T0 = hl.full((b_tile, c_tile), 1.0, x.dtype)
    T0 = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 1.0, tl.float32)
    # src[test_loops.py:N]: T1 = in_x
    in_x_0 = in_x
    # src[test_loops.py:N]: acc = w[0, c_tile][None, :] * T0 + w[1, c_tile][None, :] * T1
    load_1 = tl.load(w + (0 * 64 + indices_1 * 1), None)
    subscript = load_1[None, :]
    v_0 = subscript * T0
    load_2 = tl.load(w + (1 * 64 + indices_1 * 1), None)
    subscript_1 = load_2[None, :]
    v_1 = subscript_1 * in_x_0
    v_2 = v_0 + v_1
    # src[test_loops.py:N]: two_x = 2.0 * in_x
    v_3 = 2.0
    v_4 = in_x * v_3
    # src[test_loops.py:N]: for order in hl.tile(2, N, block_size=1):
    # src[test_loops.py:N]:     new_T = two_x * T1 - T0
    # src[test_loops.py:N]:     acc = acc + w[order, c_tile] * new_T
    # src[test_loops.py:N-N]: ...
    for offset_2 in tl.range(2, 5):
        indices_2 = offset_2 + tl.arange(0, 1).to(tl.int32)
        v_4_copy = v_4
        in_x_0_copy = in_x_0
        T0_copy = T0
        v_2_copy = v_2
        v_4_copy_0 = v_4_copy
        in_x_0_copy_0 = in_x_0_copy
        T0_copy_0 = T0_copy
        v_2_copy_0 = v_2_copy
        # src[test_loops.py:N]: new_T = two_x * T1 - T0
        v_5 = v_4_copy_0 * in_x_0_copy_0
        v_6 = v_5 - T0_copy_0
        # src[test_loops.py:N]: acc = acc + w[order, c_tile] * new_T
        load = tl.load(w + (indices_2[:, None] * 64 + indices_1[None, :] * 1), None)
        v_7 = load * v_6
        v_2 = v_2_copy_0 + v_7
        # src[test_loops.py:N]: T0 = T1
        T0 = in_x_0_copy_0
        # src[test_loops.py:N]: T1 = new_T
        in_x_0 = v_6
    # src[test_loops.py:N]: out[b_tile, c_tile] = acc
    tl.store(out + (indices_0[:, None] * 64 + indices_1[None, :] * 1), v_2, mask_0[:, None])

def chebyshev_kernel(x: torch.Tensor, w: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: B, C = x.shape
    B, C = x.shape
    # src[test_loops.py:N]: N, C = w.shape
    N, C = w.shape
    # src[test_loops.py:N]: out = torch.zeros((B, C), device=x.device, dtype=x.dtype)
    out = torch.zeros((B, C), device=x.device, dtype=x.dtype)
    # src[test_loops.py:N]: assert N >= 2, "assume N>= 2 for simplicity"
    assert N >= 2, 'assume N>= 2 for simplicity'
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    # src[test_loops.py:N]:     in_x = x[b_tile, c_tile]
    # src[test_loops.py:N]:     T0 = hl.full((b_tile, c_tile), 1.0, x.dtype)
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_chebyshev_kernel, (triton.cdiv(123, _BLOCK_SIZE_0) * triton.cdiv(64, _BLOCK_SIZE_1),), x, w, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_data_dependent_bounds1)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(end, x, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    pid_0 = tl.program_id(0)
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    # src[test_loops.py:N]: acc = hl.zeros([tile0, bs])
    acc = tl.full([_BLOCK_SIZE_1, _BLOCK_SIZE_0], 0.0, tl.float32)
    # src[test_loops.py:N]: for tile1 in hl.tile(end[0], block_size=bs):
    load = tl.load(end + tl.zeros([], tl.int32), None)
    # src[test_loops.py:N]: for tile1 in hl.tile(end[0], block_size=bs):
    # src[test_loops.py:N]:     acc += x[tile0, tile1]
    for offset_0 in tl.range(0, load.to(tl.int32), _BLOCK_SIZE_0):
        indices_0 = offset_0 + tl.arange(0, _BLOCK_SIZE_0).to(tl.int32)
        mask_0 = indices_0 < load
        acc_copy = acc
        acc_copy_0 = acc_copy
        # src[test_loops.py:N]: acc += x[tile0, tile1]
        load_1 = tl.load(x + (indices_1[:, None] * 512 + indices_0[None, :] * 1), mask_0[None, :], other=0)
        acc = acc_copy_0 + load_1
    # src[test_loops.py:N]: out[tile0] = acc.sum(-1)
    sum_1 = tl.cast(tl.sum(acc, 1), tl.float32)
    tl.store(out + indices_1 * 1, sum_1, None)

def fn(x: torch.Tensor, end: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = x.new_empty([x.size(0)])
    out = x.new_empty([x.size(0)])
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    _BLOCK_SIZE_1 = 32
    # src[test_loops.py:N]: for tile1 in hl.tile(end[0], block_size=bs):
    # src[test_loops.py:N]:     acc += x[tile0, tile1]
    _BLOCK_SIZE_0 = 32
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    # src[test_loops.py:N]:     acc = hl.zeros([tile0, bs])
    # src[test_loops.py:N]:     for tile1 in hl.tile(end[0], block_size=bs):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, (triton.cdiv(512, _BLOCK_SIZE_1),), end, x, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_data_dependent_bounds2)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(end, x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_loops.py:N]: acc = hl.zeros([tile0])
    acc = tl.full([_BLOCK_SIZE_0], 0.0, tl.float32)
    # src[test_loops.py:N]: for tile1 in hl.tile(end[0]):
    load = tl.load(end + tl.zeros([], tl.int32), None)
    # src[test_loops.py:N]: for tile1 in hl.tile(end[0]):
    # src[test_loops.py:N]:     acc += x[tile0, tile1].sum(-1)
    for offset_1 in tl.range(0, load.to(tl.int32), _BLOCK_SIZE_1):
        indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        mask_1 = indices_1 < load
        acc_copy = acc
        acc_copy_0 = acc_copy
        # src[test_loops.py:N]: acc += x[tile0, tile1].sum(-1)
        load_1 = tl.load(x + (indices_0[:, None] * 512 + indices_1[None, :] * 1), mask_1[None, :], other=0)
        sum_1 = tl.cast(tl.sum(load_1, 1), tl.float32)
        acc = acc_copy_0 + sum_1
    # src[test_loops.py:N]: out[tile0] = acc
    tl.store(tl.make_block_ptr(out, [512], [1], [offset_0], [_BLOCK_SIZE_0], [0]), acc, boundary_check=[0])

def fn(x: torch.Tensor, end: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = x.new_empty([x.size(0)])
    out = x.new_empty([x.size(0)])
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    _BLOCK_SIZE_0 = 32
    # src[test_loops.py:N]: for tile1 in hl.tile(end[0]):
    # src[test_loops.py:N]:     acc += x[tile0, tile1].sum(-1)
    _BLOCK_SIZE_1 = 32
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    # src[test_loops.py:N]:     acc = hl.zeros([tile0])
    # src[test_loops.py:N]:     for tile1 in hl.tile(end[0]):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, (triton.cdiv(512, _BLOCK_SIZE_0),), end, x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_data_dependent_bounds3)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(end0, end1, x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_loops.py:N]: acc = hl.zeros([tile0], dtype=x.dtype)
    acc = tl.full([_BLOCK_SIZE_0], 0.0, tl.float64)
    # src[test_loops.py:N]: for tile1, tile2 in hl.tile([end0[0], end1[0]]):
    load = tl.load(end0 + tl.zeros([], tl.int32), None)
    load_1 = tl.load(end1 + tl.zeros([], tl.int32), None)
    # src[test_loops.py:N]: for tile1, tile2 in hl.tile([end0[0], end1[0]]):
    # src[test_loops.py:N]:     # TODO(jansel): make this version work
    # src[test_loops.py:N]:     # acc += x[tile0, tile1, tile2].reshape(tile0, -1).sum(-1)
    # src[test_loops.py:N-N]: ...
    for offset_1 in tl.range(0, load.to(tl.int32), _BLOCK_SIZE_1):
        indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        mask_1 = indices_1 < load
        for offset_2 in tl.range(0, load_1.to(tl.int32), _BLOCK_SIZE_2):
            indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
            mask_2 = indices_2 < load_1
            acc_copy = acc
            acc_copy_0 = acc_copy
            # src[test_loops.py:N]: acc += x[tile0, tile1, tile2].sum(-1).sum(-1)
            load_2 = tl.load(x + (indices_0[:, None, None] * 65536 + indices_1[None, :, None] * 256 + indices_2[None, None, :] * 1), mask_1[None, :, None] & mask_2[None, None, :], other=0)
            sum_1 = tl.cast(tl.sum(load_2, 2), tl.float64)
            _mask_to_1 = tl.where(tl.broadcast_to(mask_1[None, :], [_BLOCK_SIZE_0, _BLOCK_SIZE_1]), sum_1, tl.full([], 0, tl.float64))
            sum_2 = tl.cast(tl.sum(_mask_to_1, 1), tl.float64)
            acc = acc_copy_0 + sum_2
    # src[test_loops.py:N]: out[tile0] = acc
    tl.store(out + indices_0 * 1, acc, None)

def fn(x: torch.Tensor, end0: torch.Tensor, end1: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = x.new_empty([x.size(0)])
    out = x.new_empty([x.size(0)])
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    _BLOCK_SIZE_0 = 32
    # src[test_loops.py:N]: for tile1, tile2 in hl.tile([end0[0], end1[0]]):
    # src[test_loops.py:N]:     # TODO(jansel): make this version work
    # src[test_loops.py:N]:     # acc += x[tile0, tile1, tile2].reshape(tile0, -1).sum(-1)
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_2 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    # src[test_loops.py:N]:     acc = hl.zeros([tile0], dtype=x.dtype)
    # src[test_loops.py:N]:     for tile1, tile2 in hl.tile([end0[0], end1[0]]):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, (triton.cdiv(32, _BLOCK_SIZE_0),), end0, end1, x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_2, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_data_dependent_bounds4)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(begin, end, x, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    pid_0 = tl.program_id(0)
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    # src[test_loops.py:N]: acc = hl.zeros([tile0, bs])
    acc = tl.full([_BLOCK_SIZE_1, _BLOCK_SIZE_0], 0.0, tl.float32)
    # src[test_loops.py:N]: for tile1 in hl.tile(begin[0], end[0], block_size=bs):
    load = tl.load(begin + tl.zeros([], tl.int32), None)
    load_1 = tl.load(end + tl.zeros([], tl.int32), None)
    # src[test_loops.py:N]: for tile1 in hl.tile(begin[0], end[0], block_size=bs):
    # src[test_loops.py:N]:     acc += x[tile0, tile1]
    for offset_0 in tl.range(load.to(tl.int32), load_1.to(tl.int32), _BLOCK_SIZE_0):
        indices_0 = offset_0 + tl.arange(0, _BLOCK_SIZE_0).to(tl.int32)
        mask_0 = indices_0 < load_1
        acc_copy = acc
        acc_copy_0 = acc_copy
        # src[test_loops.py:N]: acc += x[tile0, tile1]
        load_2 = tl.load(x + (indices_1[:, None] * 512 + indices_0[None, :] * 1), mask_0[None, :], other=0)
        acc = acc_copy_0 + load_2
    # src[test_loops.py:N]: out[tile0] = acc.sum(-1)
    sum_1 = tl.cast(tl.sum(acc, 1), tl.float32)
    tl.store(out + indices_1 * 1, sum_1, None)

def fn(x: torch.Tensor, begin: torch.Tensor, end: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = x.new_empty([x.size(0)])
    out = x.new_empty([x.size(0)])
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    _BLOCK_SIZE_1 = 32
    # src[test_loops.py:N]: for tile1 in hl.tile(begin[0], end[0], block_size=bs):
    # src[test_loops.py:N]:     acc += x[tile0, tile1]
    _BLOCK_SIZE_0 = 32
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    # src[test_loops.py:N]:     acc = hl.zeros([tile0, bs])
    # src[test_loops.py:N]:     for tile1 in hl.tile(begin[0], end[0], block_size=bs):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, (triton.cdiv(512, _BLOCK_SIZE_1),), begin, end, x, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_data_dependent_bounds5)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(begin, end, x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_loops.py:N]: acc = hl.zeros([tile0])
    acc = tl.full([_BLOCK_SIZE_0], 0.0, tl.float32)
    # src[test_loops.py:N]: for (tile1,) in hl.tile([begin[0]], [end[0]]):
    load = tl.load(begin + tl.zeros([], tl.int32), None)
    load_1 = tl.load(end + tl.zeros([], tl.int32), None)
    # src[test_loops.py:N]: for (tile1,) in hl.tile([begin[0]], [end[0]]):
    # src[test_loops.py:N]:     acc += x[tile0, tile1].sum(-1)
    for offset_1 in tl.range(load.to(tl.int32), load_1.to(tl.int32), _BLOCK_SIZE_1):
        indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        mask_1 = indices_1 < load_1
        acc_copy = acc
        acc_copy_0 = acc_copy
        # src[test_loops.py:N]: acc += x[tile0, tile1].sum(-1)
        load_2 = tl.load(x + (indices_0[:, None] * 512 + indices_1[None, :] * 1), mask_1[None, :], other=0)
        sum_1 = tl.cast(tl.sum(load_2, 1), tl.float32)
        acc = acc_copy_0 + sum_1
    # src[test_loops.py:N]: out[tile0] = acc
    tl.store(out + indices_0 * 1, acc, None)

def fn(x: torch.Tensor, begin: torch.Tensor, end: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = x.new_empty([x.size(0)])
    out = x.new_empty([x.size(0)])
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    _BLOCK_SIZE_0 = 32
    # src[test_loops.py:N]: for (tile1,) in hl.tile([begin[0]], [end[0]]):
    # src[test_loops.py:N]:     acc += x[tile0, tile1].sum(-1)
    _BLOCK_SIZE_1 = 32
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    # src[test_loops.py:N]:     acc = hl.zeros([tile0])
    # src[test_loops.py:N]:     for (tile1,) in hl.tile([begin[0]], [end[0]]):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, (triton.cdiv(512, _BLOCK_SIZE_0),), begin, end, x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_full_with_dynamic_fill_value)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_kernel_with_dynamic_fill(fill_value, x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    num_blocks_0 = tl.cdiv(4, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    # src[test_loops.py:N]: filled = hl.full((b_tile, c_tile), fill_value[0], x.dtype)
    load = tl.load(fill_value + tl.zeros([], tl.int32), None)
    filled = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], load, tl.float32)
    # src[test_loops.py:N]: out[b_tile, c_tile] = x[b_tile, c_tile] + filled
    load_1 = tl.load(x + (indices_0[:, None] * 8 + indices_1[None, :] * 1), None)
    v_0 = load_1 + filled
    tl.store(out + (indices_0[:, None] * 8 + indices_1[None, :] * 1), v_0, None)

def kernel_with_dynamic_fill(x: torch.Tensor, fill_value: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: B, C = x.shape
    B, C = x.shape
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    _BLOCK_SIZE_0 = 4
    _BLOCK_SIZE_1 = 8
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    # src[test_loops.py:N]:     # Use scalar tensor as fill value
    # src[test_loops.py:N]:     filled = hl.full((b_tile, c_tile), fill_value[0], x.dtype)
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_kernel_with_dynamic_fill, (triton.cdiv(4, _BLOCK_SIZE_0) * triton.cdiv(8, _BLOCK_SIZE_1),), fill_value, x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_l2_grouping_3d)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_3d_kernel_l2(x, y, result):
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    num_blocks_0 = 16
    num_blocks_1 = 32
    num_pid_m = 16
    num_pid_n = 32
    inner_2d_size = num_pid_m * num_pid_n
    inner_2d_pid = tl.program_id(0) % inner_2d_size
    num_pid_in_group = 4 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 4
    group_size_m = min(num_pid_m - first_pid_m, 4)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_0 = pid_0
    offset_1 = pid_1
    offset_2 = pid_2
    # src[test_loops.py:N]: result[tile] = x[tile] + y[tile]
    load = tl.load(x + (offset_0 * 2048 + offset_1 * 64 + offset_2 * 1), None)
    load_1 = tl.load(y + (offset_0 * 2048 + offset_1 * 64 + offset_2 * 1), None)
    v_0 = load + load_1
    tl.store(result + (offset_0 * 2048 + offset_1 * 64 + offset_2 * 1), v_0, None)

def add_3d_kernel_l2(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    # src[test_loops.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_3d_kernel_l2, (16 * 32 * 64,), x, y, result, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return result
    return result

--- assertExpectedJournal(TestLoops.test_l2_grouping_4d)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_4d_kernel_l2(x, y, result):
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    num_blocks_0 = 8
    num_blocks_1 = 16
    num_blocks_2 = 32
    num_pid_m = 8
    num_pid_n = 16
    inner_2d_size = num_pid_m * num_pid_n
    inner_2d_pid = tl.program_id(0) % inner_2d_size
    num_pid_in_group = 2 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 2
    group_size_m = min(num_pid_m - first_pid_m, 2)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1) % num_blocks_2
    pid_3 = tl.program_id(0) // (num_blocks_0 * num_blocks_1 * num_blocks_2)
    offset_0 = pid_0
    offset_1 = pid_1
    offset_2 = pid_2
    offset_3 = pid_3
    # src[test_loops.py:N]: result[tile] = x[tile] + y[tile]
    load = tl.load(x + (offset_0 * 32768 + offset_1 * 2048 + offset_2 * 64 + offset_3 * 1), None)
    load_1 = tl.load(y + (offset_0 * 32768 + offset_1 * 2048 + offset_2 * 64 + offset_3 * 1), None)
    v_0 = load + load_1
    tl.store(result + (offset_0 * 32768 + offset_1 * 2048 + offset_2 * 64 + offset_3 * 1), v_0, None)

def add_4d_kernel_l2(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    # src[test_loops.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_4d_kernel_l2, (8 * 16 * 32 * 64,), x, y, result, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return result
    return result

--- assertExpectedJournal(TestLoops.test_l2_grouping_with_loop_order)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_3d_kernel_reordered(x, y, result):
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    num_blocks_0 = 32
    num_blocks_1 = 16
    num_pid_m = 32
    num_pid_n = 16
    inner_2d_size = num_pid_m * num_pid_n
    inner_2d_pid = tl.program_id(0) % inner_2d_size
    num_pid_in_group = 4 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 4
    group_size_m = min(num_pid_m - first_pid_m, 4)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_2 = pid_0
    offset_1 = pid_1
    offset_0 = pid_2
    # src[test_loops.py:N]: result[tile] = x[tile] + y[tile]
    load = tl.load(x + (offset_0 * 512 + offset_1 * 32 + offset_2 * 1), None)
    load_1 = tl.load(y + (offset_0 * 512 + offset_1 * 32 + offset_2 * 1), None)
    v_0 = load + load_1
    tl.store(result + (offset_0 * 512 + offset_1 * 32 + offset_2 * 1), v_0, None)

def add_3d_kernel_reordered(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    # src[test_loops.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_3d_kernel_reordered, (32 * 16 * 8,), x, y, result, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return result
    return result

--- assertExpectedJournal(TestLoops.test_l2_grouping_with_register_block_size)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    num_pid_m = tl.cdiv(2048, _BLOCK_SIZE_0)
    num_pid_n = tl.cdiv(2048, _BLOCK_SIZE_1)
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 8 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 8
    group_size_m = min(num_pid_m - first_pid_m, 8)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_0 = pid_0 * _BLOCK_SIZE_0
    offset_1 = pid_1 * _BLOCK_SIZE_1
    # src[test_loops.py:N]: out[tile0, tile1] = x[tile0, tile1] + 1
    load = tl.load(tl.make_block_ptr(x, [2048, 2048], [2048, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), boundary_check=[0, 1], padding_option='zero')
    v_0 = 1.0
    v_1 = load + v_0
    tl.store(tl.make_block_ptr(out, [2048, 2048], [2048, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), v_1, boundary_check=[0, 1])

def fn(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    # src[test_loops.py:N]:     out[tile0, tile1] = x[tile0, tile1] + 1
    _launcher(_helion_fn, (triton.cdiv(2048, _BLOCK_SIZE_0) * triton.cdiv(2048, _BLOCK_SIZE_1),), x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_loop_arg_block)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime.triton_helpers import math as tl_math
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(x, out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_loops.py:N]: for tile_a in hl.tile(a, block_size=block_size):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    # src[test_loops.py:N]: out[tile_a] = torch.sin(x[tile_a])
    load = tl.load(tl.make_block_ptr(x, [1024], [1], [offset_0], [_BLOCK_SIZE_0], [0]), boundary_check=[0], padding_option='zero')
    v_0 = tl_math.sin(load)
    tl.store(tl.make_block_ptr(out, [1024], [1], [offset_0], [_BLOCK_SIZE_0], [0]), v_0, boundary_check=[0])

def fn(x: torch.Tensor, block_size: int, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: (a,) = x.shape
    a, = x.shape
    # src[test_loops.py:N]: for tile_a in hl.tile(a, block_size=block_size):
    _BLOCK_SIZE_0 = block_size
    # src[test_loops.py:N]: for tile_a in hl.tile(a, block_size=block_size):
    # src[test_loops.py:N]:     out[tile_a] = torch.sin(x[tile_a])
    _launcher(_helion_fn, (triton.cdiv(1024, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_loop_fixed_block)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime.triton_helpers import math as tl_math
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    # src[test_loops.py:N]: for tile_a, tile_b in hl.tile([a, b], block_size=[4, 8]):
    num_blocks_0 = tl.cdiv(128, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    offset_1 = pid_1 * _BLOCK_SIZE_1
    # src[test_loops.py:N]: for tile_c in hl.tile(c, block_size=16):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c] = torch.sin(x[tile_a, tile_b, tile_c])
    for offset_2 in tl.range(0, 128, _BLOCK_SIZE_2):
        # src[test_loops.py:N]: out[tile_a, tile_b, tile_c] = torch.sin(x[tile_a, tile_b, tile_c])
        load = tl.load(tl.make_block_ptr(x, [128, 128, 128], [16384, 128, 1], [offset_0, offset_1, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2], [2, 1, 0]), boundary_check=[0, 1, 2], padding_option='zero')
        v_0 = tl_math.sin(load)
        tl.store(tl.make_block_ptr(out, [128, 128, 128], [16384, 128, 1], [offset_0, offset_1, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2], [2, 1, 0]), v_0, boundary_check=[0, 1, 2])

def fn(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: a, b, c = x.shape
    a, b, c = x.shape
    # src[test_loops.py:N]: for tile_a, tile_b in hl.tile([a, b], block_size=[4, 8]):
    _BLOCK_SIZE_0 = 4
    _BLOCK_SIZE_1 = 8
    # src[test_loops.py:N]: for tile_c in hl.tile(c, block_size=16):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c] = torch.sin(x[tile_a, tile_b, tile_c])
    _BLOCK_SIZE_2 = 16
    # src[test_loops.py:N]: for tile_a, tile_b in hl.tile([a, b], block_size=[4, 8]):
    # src[test_loops.py:N]:     for tile_c in hl.tile(c, block_size=16):
    # src[test_loops.py:N]:         out[tile_a, tile_b, tile_c] = torch.sin(x[tile_a, tile_b, tile_c])
    _launcher(_helion_fn, (triton.cdiv(128, _BLOCK_SIZE_0) * triton.cdiv(128, _BLOCK_SIZE_1),), x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_loop_unroll1)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(x, out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_loops.py:N]: out[tile] = x[tile]
    load = tl.load(x + indices_0 * 1, None)
    tl.store(out + indices_0 * 1, load, None)
    # src[test_loops.py:N]: out[tile] += i
    load_1 = tl.load(out + indices_0 * 1, None)
    v_0 = 1.0
    v_1 = load_1 + v_0
    tl.store(out + indices_0 * 1, v_1, None)
    load_2 = tl.load(out + indices_0 * 1, None)
    v_2 = 2.0
    v_3 = load_2 + v_2
    tl.store(out + indices_0 * 1, v_3, None)
    load_3 = tl.load(out + indices_0 * 1, None)
    v_4 = 3.0
    v_5 = load_3 + v_4
    tl.store(out + indices_0 * 1, v_5, None)

def fn(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.zeros_like(x)
    out = torch.zeros_like(x)
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    _BLOCK_SIZE_0 = 4
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    # src[test_loops.py:N]:     out[tile] = x[tile]
    # src[test_loops.py:N]:     for i in [1, 2, 3]:
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, (triton.cdiv(4, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_loop_unroll2)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(x, out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_loops.py:N]: out[tile] = x[tile]
    load = tl.load(x + indices_0 * 1, None)
    tl.store(out + indices_0 * 1, load, None)
    # src[test_loops.py:N]: out[tile] += i
    load_1 = tl.load(out + indices_0 * 1, None)
    v_0 = 1.0
    v_1 = load_1 + v_0
    tl.store(out + indices_0 * 1, v_1, None)
    load_2 = tl.load(out + indices_0 * 1, None)
    v_2 = 2.0
    v_3 = load_2 + v_2
    tl.store(out + indices_0 * 1, v_3, None)
    load_3 = tl.load(out + indices_0 * 1, None)
    v_4 = 3.0
    v_5 = load_3 + v_4
    tl.store(out + indices_0 * 1, v_5, None)

def fn(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.zeros_like(x)
    out = torch.zeros_like(x)
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    _BLOCK_SIZE_0 = 4
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    # src[test_loops.py:N]:     out[tile] = x[tile]
    # src[test_loops.py:N]:     for i in (a, b, c):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, (triton.cdiv(4, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_multiple_for_loop_1d)
from __future__ import annotations

import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_addToBoth(x0, x1, x2, c0, c1, c2, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    # src[test_loops.py:N]: for tile in hl.tile(x0.size()):
    # src[test_loops.py:N]:     x0[tile] += c0
    pid_shared = tl.program_id(0)
    if pid_shared < tl.cdiv(5, _BLOCK_SIZE_0):
        # src[test_loops.py:N]: for tile in hl.tile(x0.size()):
        pid_0 = pid_shared
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < 5
        # src[test_loops.py:N]: x0[tile] += c0
        load = tl.load(x0 + indices_0 * 1, mask_0, other=0)
        v_0 = tl.cast(c0, tl.float32)
        v_1 = load + v_0
        tl.store(x0 + indices_0 * 1, v_1, mask_0)
    elif pid_shared < tl.cdiv(5, _BLOCK_SIZE_0) + tl.cdiv(5, _BLOCK_SIZE_1):
        # src[test_loops.py:N]: for tile in hl.tile(x1.size()):
        pid_shared -= tl.cdiv(5, _BLOCK_SIZE_0)
        pid_1 = pid_shared
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < 5
        # src[test_loops.py:N]: x1[tile] += c1
        load_1 = tl.load(x1 + indices_1 * 1, mask_1, other=0)
        v_2 = tl.cast(c1, tl.float32)
        v_3 = load_1 + v_2
        tl.store(x1 + indices_1 * 1, v_3, mask_1)
    else:
        # src[test_loops.py:N]: for tile in hl.tile(x2.size()):
        pid_shared -= tl.cdiv(5, _BLOCK_SIZE_0) + tl.cdiv(5, _BLOCK_SIZE_1)
        pid_2 = pid_shared
        offset_2 = pid_2 * _BLOCK_SIZE_2
        indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
        mask_2 = indices_2 < 5
        # src[test_loops.py:N]: x2[tile] += c2
        load_2 = tl.load(x2 + indices_2 * 1, mask_2, other=0)
        v_4 = tl.cast(c2, tl.float32)
        v_5 = load_2 + v_4
        tl.store(x2 + indices_2 * 1, v_5, mask_2)

def addToBoth(a, b, c, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: x0, c0 = a
    x0, c0 = a
    # src[test_loops.py:N]: x1, c1 = b
    x1, c1 = b
    # src[test_loops.py:N]: x2, c2 = c
    x2, c2 = c
    # src[test_loops.py:N]: for tile in hl.tile(x0.size()):
    _BLOCK_SIZE_0 = 8
    # src[test_loops.py:N]: for tile in hl.tile(x1.size()):
    _BLOCK_SIZE_1 = 8
    # src[test_loops.py:N]: for tile in hl.tile(x2.size()):
    _BLOCK_SIZE_2 = 8
    # src[test_loops.py:N]: for tile in hl.tile(x2.size()):
    # src[test_loops.py:N]:     x2[tile] += c2
    _launcher(_helion_addToBoth, (triton.cdiv(5, _BLOCK_SIZE_0) + triton.cdiv(5, _BLOCK_SIZE_1) + triton.cdiv(5, _BLOCK_SIZE_2),), x0, x1, x2, c0, c1, c2, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return x0, x1, x2
    return (x0, x1, x2)

--- assertExpectedJournal(TestLoops.test_multiple_for_loop_2d)
from __future__ import annotations

import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_addToBoth(x0, x1, x2, c0, c1, c2, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr, _BLOCK_SIZE_5: tl.constexpr):
    # src[test_loops.py:N]: for tile_n in hl.tile(a_n):
    # src[test_loops.py:N]:     for tile_m in hl.tile(a_m):
    # src[test_loops.py:N]:         x0[tile_n, tile_m] += c0
    pid_shared = tl.program_id(0)
    if pid_shared < tl.cdiv(5, _BLOCK_SIZE_0):
        # src[test_loops.py:N]: for tile_n in hl.tile(a_n):
        pid_0 = pid_shared
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < 5
        # src[test_loops.py:N]: for tile_m in hl.tile(a_m):
        # src[test_loops.py:N]:     x0[tile_n, tile_m] += c0
        for offset_1 in tl.range(0, 10, _BLOCK_SIZE_1):
            indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
            mask_1 = indices_1 < 10
            # src[test_loops.py:N]: x0[tile_n, tile_m] += c0
            load = tl.load(x0 + (indices_0[:, None] * 10 + indices_1[None, :] * 1), mask_0[:, None] & mask_1[None, :], other=0)
            v_0 = tl.cast(c0, tl.float32)
            v_1 = load + v_0
            tl.store(x0 + (indices_0[:, None] * 10 + indices_1[None, :] * 1), v_1, mask_0[:, None] & mask_1[None, :])
    elif pid_shared < tl.cdiv(5, _BLOCK_SIZE_0) + tl.cdiv(5, _BLOCK_SIZE_2):
        # src[test_loops.py:N]: for tile_n in hl.tile(b_n):
        pid_shared -= tl.cdiv(5, _BLOCK_SIZE_0)
        pid_1 = pid_shared
        offset_2 = pid_1 * _BLOCK_SIZE_2
        indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
        mask_2 = indices_2 < 5
        # src[test_loops.py:N]: for tile_m in hl.tile(b_m):
        # src[test_loops.py:N]:     x1[tile_n, tile_m] += c1
        for offset_3 in tl.range(0, 10, _BLOCK_SIZE_3):
            indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
            mask_3 = indices_3 < 10
            # src[test_loops.py:N]: x1[tile_n, tile_m] += c1
            load_1 = tl.load(x1 + (indices_2[:, None] * 10 + indices_3[None, :] * 1), mask_2[:, None] & mask_3[None, :], other=0)
            v_2 = tl.cast(c1, tl.float32)
            v_3 = load_1 + v_2
            tl.store(x1 + (indices_2[:, None] * 10 + indices_3[None, :] * 1), v_3, mask_2[:, None] & mask_3[None, :])
    else:
        # src[test_loops.py:N]: for tile_n in hl.tile(c_n):
        pid_shared -= tl.cdiv(5, _BLOCK_SIZE_0) + tl.cdiv(5, _BLOCK_SIZE_2)
        pid_2 = pid_shared
        offset_4 = pid_2 * _BLOCK_SIZE_4
        indices_4 = (offset_4 + tl.arange(0, _BLOCK_SIZE_4)).to(tl.int32)
        mask_4 = indices_4 < 5
        # src[test_loops.py:N]: for tile_m in hl.tile(c_m):
        # src[test_loops.py:N]:     x2[tile_n, tile_m] += c2
        for offset_5 in tl.range(0, 10, _BLOCK_SIZE_5):
            indices_5 = offset_5 + tl.arange(0, _BLOCK_SIZE_5).to(tl.int32)
            mask_5 = indices_5 < 10
            # src[test_loops.py:N]: x2[tile_n, tile_m] += c2
            load_2 = tl.load(x2 + (indices_4[:, None] * 10 + indices_5[None, :] * 1), mask_4[:, None] & mask_5[None, :], other=0)
            v_4 = tl.cast(c2, tl.float32)
            v_5 = load_2 + v_4
            tl.store(x2 + (indices_4[:, None] * 10 + indices_5[None, :] * 1), v_5, mask_4[:, None] & mask_5[None, :])

def addToBoth(a, b, c, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: x0, c0 = a
    x0, c0 = a
    # src[test_loops.py:N]: x1, c1 = b
    x1, c1 = b
    # src[test_loops.py:N]: x2, c2 = c
    x2, c2 = c
    # src[test_loops.py:N]: a_n, a_m = x0.shape
    a_n, a_m = x0.shape
    # src[test_loops.py:N]: b_n, b_m = x1.shape
    b_n, b_m = x1.shape
    # src[test_loops.py:N]: c_n, c_m = x2.shape
    c_n, c_m = x2.shape
    # src[test_loops.py:N]: for tile_n in hl.tile(a_n):
    _BLOCK_SIZE_0 = 8
    # src[test_loops.py:N]: for tile_m in hl.tile(a_m):
    # src[test_loops.py:N]:     x0[tile_n, tile_m] += c0
    _BLOCK_SIZE_1 = 16
    # src[test_loops.py:N]: for tile_n in hl.tile(b_n):
    _BLOCK_SIZE_2 = 8
    # src[test_loops.py:N]: for tile_m in hl.tile(b_m):
    # src[test_loops.py:N]:     x1[tile_n, tile_m] += c1
    _BLOCK_SIZE_3 = 16
    # src[test_loops.py:N]: for tile_n in hl.tile(c_n):
    _BLOCK_SIZE_4 = 8
    # src[test_loops.py:N]: for tile_m in hl.tile(c_m):
    # src[test_loops.py:N]:     x2[tile_n, tile_m] += c2
    _BLOCK_SIZE_5 = 16
    # src[test_loops.py:N]: for tile_n in hl.tile(c_n):
    # src[test_loops.py:N]:     for tile_m in hl.tile(c_m):
    # src[test_loops.py:N]:         x2[tile_n, tile_m] += c2
    _launcher(_helion_addToBoth, (triton.cdiv(5, _BLOCK_SIZE_0) + triton.cdiv(5, _BLOCK_SIZE_2) + triton.cdiv(5, _BLOCK_SIZE_4),), x0, x1, x2, c0, c1, c2, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, _BLOCK_SIZE_4, _BLOCK_SIZE_5, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return x0, x1, x2
    return (x0, x1, x2)

--- assertExpectedJournal(TestLoops.test_multiple_for_loop_2d_multiple_tile)
from __future__ import annotations

import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_addToBoth(x0, x1, x2, c0, c1, c2, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr, _BLOCK_SIZE_5: tl.constexpr):
    # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([a_n, a_m]):
    # src[test_loops.py:N]:     x0[tile_n, tile_m] += c0
    pid_shared = tl.program_id(0)
    if pid_shared < tl.cdiv(5, _BLOCK_SIZE_0) * tl.cdiv(10, _BLOCK_SIZE_1):
        # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([a_n, a_m]):
        num_blocks_0 = tl.cdiv(5, _BLOCK_SIZE_0)
        pid_0 = pid_shared % num_blocks_0
        pid_1 = pid_shared // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < 5
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < 10
        # src[test_loops.py:N]: x0[tile_n, tile_m] += c0
        load = tl.load(x0 + (indices_0[:, None] * 10 + indices_1[None, :] * 1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = tl.cast(c0, tl.float32)
        v_1 = load + v_0
        tl.store(x0 + (indices_0[:, None] * 10 + indices_1[None, :] * 1), v_1, mask_0[:, None] & mask_1[None, :])
    elif pid_shared < tl.cdiv(5, _BLOCK_SIZE_0) * tl.cdiv(10, _BLOCK_SIZE_1) + tl.cdiv(5, _BLOCK_SIZE_2) * tl.cdiv(10, _BLOCK_SIZE_3):
        # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([b_n, b_m]):
        pid_shared -= tl.cdiv(5, _BLOCK_SIZE_0) * tl.cdiv(10, _BLOCK_SIZE_1)
        num_blocks_1 = tl.cdiv(5, _BLOCK_SIZE_2)
        pid_2 = pid_shared % num_blocks_1
        pid_3 = pid_shared // num_blocks_1
        offset_2 = pid_2 * _BLOCK_SIZE_2
        indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
        mask_2 = indices_2 < 5
        offset_3 = pid_3 * _BLOCK_SIZE_3
        indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
        mask_3 = indices_3 < 10
        # src[test_loops.py:N]: x1[tile_n, tile_m] += c1
        load_1 = tl.load(x1 + (indices_2[:, None] * 10 + indices_3[None, :] * 1), mask_2[:, None] & mask_3[None, :], other=0)
        v_2 = tl.cast(c1, tl.float32)
        v_3 = load_1 + v_2
        tl.store(x1 + (indices_2[:, None] * 10 + indices_3[None, :] * 1), v_3, mask_2[:, None] & mask_3[None, :])
    else:
        # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([c_n, c_m]):
        pid_shared -= tl.cdiv(5, _BLOCK_SIZE_0) * tl.cdiv(10, _BLOCK_SIZE_1) + tl.cdiv(5, _BLOCK_SIZE_2) * tl.cdiv(10, _BLOCK_SIZE_3)
        num_blocks_2 = tl.cdiv(5, _BLOCK_SIZE_4)
        pid_4 = pid_shared % num_blocks_2
        pid_5 = pid_shared // num_blocks_2
        offset_4 = pid_4 * _BLOCK_SIZE_4
        indices_4 = (offset_4 + tl.arange(0, _BLOCK_SIZE_4)).to(tl.int32)
        mask_4 = indices_4 < 5
        offset_5 = pid_5 * _BLOCK_SIZE_5
        indices_5 = (offset_5 + tl.arange(0, _BLOCK_SIZE_5)).to(tl.int32)
        mask_5 = indices_5 < 10
        # src[test_loops.py:N]: x2[tile_n, tile_m] += c2
        load_2 = tl.load(x2 + (indices_4[:, None] * 10 + indices_5[None, :] * 1), mask_4[:, None] & mask_5[None, :], other=0)
        v_4 = tl.cast(c2, tl.float32)
        v_5 = load_2 + v_4
        tl.store(x2 + (indices_4[:, None] * 10 + indices_5[None, :] * 1), v_5, mask_4[:, None] & mask_5[None, :])

def addToBoth(a, b, c, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: x0, c0 = a
    x0, c0 = a
    # src[test_loops.py:N]: x1, c1 = b
    x1, c1 = b
    # src[test_loops.py:N]: x2, c2 = c
    x2, c2 = c
    # src[test_loops.py:N]: a_n, a_m = x0.shape
    a_n, a_m = x0.shape
    # src[test_loops.py:N]: b_n, b_m = x1.shape
    b_n, b_m = x1.shape
    # src[test_loops.py:N]: c_n, c_m = x2.shape
    c_n, c_m = x2.shape
    # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([a_n, a_m]):
    _BLOCK_SIZE_0 = 8
    _BLOCK_SIZE_1 = 16
    # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([b_n, b_m]):
    _BLOCK_SIZE_2 = 8
    _BLOCK_SIZE_3 = 16
    # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([c_n, c_m]):
    _BLOCK_SIZE_4 = 8
    _BLOCK_SIZE_5 = 16
    # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([c_n, c_m]):
    # src[test_loops.py:N]:     x2[tile_n, tile_m] += c2
    _launcher(_helion_addToBoth, (triton.cdiv(5, _BLOCK_SIZE_0) * triton.cdiv(10, _BLOCK_SIZE_1) + triton.cdiv(5, _BLOCK_SIZE_2) * triton.cdiv(10, _BLOCK_SIZE_3) + triton.cdiv(5, _BLOCK_SIZE_4) * triton.cdiv(10, _BLOCK_SIZE_5),), x0, x1, x2, c0, c1, c2, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, _BLOCK_SIZE_4, _BLOCK_SIZE_5, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return x0, x1, x2
    return (x0, x1, x2)

--- assertExpectedJournal(TestLoops.test_nested_loop_accumulator)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_nested_loop_accumulator(x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr):
    # src[test_loops.py:N]: for tile_b in hl.tile(B):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0
    indices_0 = offset_0 + tl.zeros([1], tl.int32)
    # src[test_loops.py:N]: acc = hl.zeros([tile_b], dtype=torch.float32)
    acc = tl.full([_BLOCK_SIZE_0], 0.0, tl.float32)
    # src[test_loops.py:N]: for tile_n in hl.tile(N):
    # src[test_loops.py:N]:     for tile_m in hl.tile(M):
    # src[test_loops.py:N]:         vals = x[tile_b, tile_n, tile_m].to(torch.float32)
    # src[test_loops.py:N-N]: ...
    for offset_1 in tl.range(0, 4, _BLOCK_SIZE_1):
        indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        acc_copy = acc
        acc = acc_copy
        # src[test_loops.py:N]: for tile_m in hl.tile(M):
        # src[test_loops.py:N]:     vals = x[tile_b, tile_n, tile_m].to(torch.float32)
        # src[test_loops.py:N]:     # Accumulate sum
        # src[test_loops.py:N-N]: ...
        for offset_2 in tl.range(0, 8, _BLOCK_SIZE_2):
            indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
            acc_copy_0_copy = acc
            acc_copy_0_copy_0 = acc_copy_0_copy
            # src[test_loops.py:N]: vals = x[tile_b, tile_n, tile_m].to(torch.float32)
            vals = tl.load(x + (indices_0[:, None, None] * 32 + indices_1[None, :, None] * 8 + indices_2[None, None, :] * 1), None)
            # src[test_loops.py:N]: acc = acc + vals.sum(dim=2).sum(dim=1)
            sum_1 = tl.cast(tl.sum(vals, 2), tl.float32)
            sum_2 = tl.cast(tl.sum(sum_1, 1), tl.float32)
            acc = acc_copy_0_copy_0 + sum_2
    # src[test_loops.py:N]: avg = acc / (N * M)
    v_1 = 0.03125
    v_2 = acc * v_1
    # src[test_loops.py:N]: for tile_n in hl.tile(N):
    # src[test_loops.py:N]:     for tile_m in hl.tile(M):
    # src[test_loops.py:N]:         vals = x[tile_b, tile_n, tile_m].to(torch.float32)
    # src[test_loops.py:N-N]: ...
    for offset_3 in tl.range(0, 4, _BLOCK_SIZE_3):
        indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
        v_2_copy = v_2
        v_2_copy_0 = v_2_copy
        # src[test_loops.py:N]: for tile_m in hl.tile(M):
        # src[test_loops.py:N]:     vals = x[tile_b, tile_n, tile_m].to(torch.float32)
        # src[test_loops.py:N]:     result = vals - avg[:, None, None]
        # src[test_loops.py:N-N]: ...
        for offset_4 in tl.range(0, 8, _BLOCK_SIZE_4):
            indices_4 = offset_4 + tl.arange(0, _BLOCK_SIZE_4).to(tl.int32)
            v_2_copy_0_copy = v_2_copy_0
            v_2_copy_0_copy_0 = v_2_copy_0_copy
            # src[test_loops.py:N]: vals = x[tile_b, tile_n, tile_m].to(torch.float32)
            vals_1 = tl.load(x + (indices_0[:, None, None] * 32 + indices_3[None, :, None] * 8 + indices_4[None, None, :] * 1), None)
            # src[test_loops.py:N]: result = vals - avg[:, None, None]
            subscript = v_2_copy_0_copy_0[:, None, None]
            v_3 = vals_1 - subscript
            # src[test_loops.py:N]: out[tile_b, tile_n, tile_m] = result.to(x.dtype)
            tl.store(out + (indices_0[:, None, None] * 32 + indices_3[None, :, None] * 8 + indices_4[None, None, :] * 1), v_3, None)

def nested_loop_accumulator(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: B, N, M = x.size()
    B, N, M = x.size()
    # src[test_loops.py:N]: out = torch.zeros_like(x)
    out = torch.zeros_like(x)
    # src[test_loops.py:N]: acc = hl.zeros([tile_b], dtype=torch.float32)
    _BLOCK_SIZE_0 = 1
    # src[test_loops.py:N]: for tile_n in hl.tile(N):
    # src[test_loops.py:N]:     for tile_m in hl.tile(M):
    # src[test_loops.py:N]:         vals = x[tile_b, tile_n, tile_m].to(torch.float32)
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_1 = 2
    # src[test_loops.py:N]: for tile_m in hl.tile(M):
    # src[test_loops.py:N]:     vals = x[tile_b, tile_n, tile_m].to(torch.float32)
    # src[test_loops.py:N]:     # Accumulate sum
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_2 = 4
    # src[test_loops.py:N]: for tile_n in hl.tile(N):
    # src[test_loops.py:N]:     for tile_m in hl.tile(M):
    # src[test_loops.py:N]:         vals = x[tile_b, tile_n, tile_m].to(torch.float32)
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_3 = 2
    # src[test_loops.py:N]: for tile_m in hl.tile(M):
    # src[test_loops.py:N]:     vals = x[tile_b, tile_n, tile_m].to(torch.float32)
    # src[test_loops.py:N]:     result = vals - avg[:, None, None]
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_4 = 4
    # src[test_loops.py:N]: for tile_b in hl.tile(B):
    # src[test_loops.py:N]:     # Initialize accumulator for this batch
    # src[test_loops.py:N]:     acc = hl.zeros([tile_b], dtype=torch.float32)
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_nested_loop_accumulator, (2,), x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, _BLOCK_SIZE_4, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_pointwise_device_loop)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_pointwise_device_loop(x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[basic_kernels.py:N]: for tile_n in hl.tile(n):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[basic_kernels.py:N]: for tile_m in hl.tile(m):
    # src[basic_kernels.py:N]:     out[tile_n, tile_m] = torch.sigmoid(x[tile_n, tile_m] + 1)
    for offset_1 in tl.range(0, 512, _BLOCK_SIZE_1):
        indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        # src[basic_kernels.py:N]: out[tile_n, tile_m] = torch.sigmoid(x[tile_n, tile_m] + 1)
        load = tl.load(x + (indices_0[:, None] * 512 + indices_1[None, :] * 1), None)
        v_0 = 1.0
        v_1 = load + v_0
        v_2 = tl.sigmoid(tl.cast(v_1, tl.float32))
        tl.store(out + (indices_0[:, None] * 512 + indices_1[None, :] * 1), v_2, None)

def pointwise_device_loop(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[basic_kernels.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[basic_kernels.py:N]: n, m = x.shape
    n, m = x.shape
    # src[basic_kernels.py:N]: for tile_n in hl.tile(n):
    _BLOCK_SIZE_0 = 32
    # src[basic_kernels.py:N]: for tile_m in hl.tile(m):
    # src[basic_kernels.py:N]:     out[tile_n, tile_m] = torch.sigmoid(x[tile_n, tile_m] + 1)
    _BLOCK_SIZE_1 = 32
    # src[basic_kernels.py:N]: for tile_n in hl.tile(n):
    # src[basic_kernels.py:N]:     for tile_m in hl.tile(m):
    # src[basic_kernels.py:N]:         out[tile_n, tile_m] = torch.sigmoid(x[tile_n, tile_m] + 1)
    _launcher(_helion_pointwise_device_loop, (triton.cdiv(512, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[basic_kernels.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_range_unroll_factors)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_nested_loop_kernel(x, out, x_size_0, x_size_1, out_stride_0, out_stride_1, x_stride_0, x_stride_1, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_loops.py:N]: for tile_outer in hl.tile(x.size(0)):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    # src[test_loops.py:N]: for tile_inner in hl.tile(x.size(1)):
    # src[test_loops.py:N]:     out[tile_outer, tile_inner] = x[tile_outer, tile_inner] + 1
    for offset_1 in tl.range(0, x_size_1.to(tl.int32), _BLOCK_SIZE_1, loop_unroll_factor=2):
        indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        # src[test_loops.py:N]: out[tile_outer, tile_inner] = x[tile_outer, tile_inner] + 1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(out + (indices_0[:, None] * out_stride_0 + indices_1[None, :] * out_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def nested_loop_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: for tile_outer in hl.tile(x.size(0)):
    _BLOCK_SIZE_0 = 32
    # src[test_loops.py:N]: for tile_inner in hl.tile(x.size(1)):
    # src[test_loops.py:N]:     out[tile_outer, tile_inner] = x[tile_outer, tile_inner] + 1
    _BLOCK_SIZE_1 = 16
    # src[test_loops.py:N]: for tile_outer in hl.tile(x.size(0)):
    # src[test_loops.py:N]:     # Inner loop becomes device loop with tl.range
    # src[test_loops.py:N]:     for tile_inner in hl.tile(x.size(1)):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_nested_loop_kernel, (triton.cdiv(x.size(0), _BLOCK_SIZE_0),), x, out, x.size(0), x.size(1), out.stride(0), out.stride(1), x.stride(0), x.stride(1), _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_register_block_size_codegen_size_hint)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_kernel_fixed_block_size(loss_sum, y_true, kl_loss, loss, loss_sum_stride_0, _BLOCK_SIZE_1: tl.constexpr, _RDIM_SIZE_2: tl.constexpr, _RDIM_SIZE_3: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_loops.py:N]: for tile_bt in hl.tile(BT, block_size=BT_SIZE):
    pid_0 = tl.program_id(0)
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    indices_5 = tl.arange(0, _RDIM_SIZE_2).to(tl.int32)
    indices_6 = tl.arange(0, _RDIM_SIZE_3).to(tl.int32)
    mask_3 = indices_6 < _BLOCK_SIZE_0
    # src[test_loops.py:N]: loss_sum[:, :] = hl.zeros([BT_SIZE, block_size_n], dtype=torch.float32)
    full = tl.full([64, _BLOCK_SIZE_0], 0.0, tl.float32)
    tl.store(loss_sum + (indices_5[:, None] * loss_sum_stride_0 + indices_6[None, :] * 1), full, mask_3[None, :])
    # src[test_loops.py:N]: for tile_v in hl.tile(V_local, block_size=block_size_n):
    # src[test_loops.py:N]:     y_true_val = y_true[tile_bt, tile_v]
    # src[test_loops.py:N]:     kl_loss[tile_bt, tile_v] = y_true_val
    # src[test_loops.py:N-N]: ...
    for offset_4 in tl.range(0, 128, _BLOCK_SIZE_0):
        indices_4 = offset_4 + tl.arange(0, _BLOCK_SIZE_0).to(tl.int32)
        # src[test_loops.py:N]: y_true_val = y_true[tile_bt, tile_v]
        y_true_val = tl.load(y_true + (indices_1[:, None] * 128 + indices_4[None, :] * 1), None)
        # src[test_loops.py:N]: kl_loss[tile_bt, tile_v] = y_true_val
        tl.store(kl_loss + (indices_1[:, None] * 128 + indices_4[None, :] * 1), y_true_val, None)
        # src[test_loops.py:N]: hl.atomic_add(loss_sum, [tile_bt, tile_v], kl_loss[tile_bt, tile_v])
        load_1 = tl.load(kl_loss + (indices_1[:, None] * 128 + indices_4[None, :] * 1), None)
        tl.atomic_add(loss_sum + (indices_1[:, None] * loss_sum_stride_0 + indices_4[None, :] * 1), load_1, mask=None, sem='relaxed')
    # src[test_loops.py:N]: loss[tile_bt] = loss_sum[:, :].sum(dim=-1)
    load = tl.load(loss_sum + (indices_5[:, None] * loss_sum_stride_0 + indices_6[None, :] * 1), mask_3[None, :], other=0)
    sum_1 = tl.cast(tl.sum(load, 1), tl.float32)
    tl.store(loss + indices_1 * 1, sum_1, None)

def kernel_fixed_block_size(y_pred: torch.Tensor, y_true: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: BT, V_local = y_pred.shape
    BT, V_local = y_pred.shape
    # src[test_loops.py:N]: loss = torch.zeros((BT,), dtype=torch.float32, device=y_pred.device)
    loss = torch.zeros((BT,), dtype=torch.float32, device=y_pred.device)
    # src[test_loops.py:N]: kl_loss = torch.zeros_like(y_pred)
    kl_loss = torch.zeros_like(y_pred)
    # src[test_loops.py:N]: block_size_n = hl.register_block_size(V_local)
    block_size_n = 128
    # src[test_loops.py:N]: BT_SIZE = 64
    BT_SIZE = 64
    # src[test_loops.py:N]: loss_sum = torch.zeros(
    # src[test_loops.py:N]:     [BT_SIZE, block_size_n], dtype=torch.float32, device=y_pred.device
    # src[test_loops.py:N]: )
    loss_sum = torch.zeros([BT_SIZE, block_size_n], dtype=torch.float32, device=y_pred.device)
    # src[test_loops.py:N]: for tile_bt in hl.tile(BT, block_size=BT_SIZE):
    _BLOCK_SIZE_1 = 64
    _RDIM_SIZE_2 = 64
    # src[test_loops.py:N]: for tile_v in hl.tile(V_local, block_size=block_size_n):
    # src[test_loops.py:N]:     y_true_val = y_true[tile_bt, tile_v]
    # src[test_loops.py:N]:     kl_loss[tile_bt, tile_v] = y_true_val
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_0 = 128
    # src[test_loops.py:N]: for tile_bt in hl.tile(BT, block_size=BT_SIZE):
    # src[test_loops.py:N]:     loss_sum[:, :] = hl.zeros([BT_SIZE, block_size_n], dtype=torch.float32)
    # src[test_loops.py:N]:     for tile_v in hl.tile(V_local, block_size=block_size_n):
    # src[test_loops.py:N-N]: ...
    _RDIM_SIZE_3 = triton.next_power_of_2(_BLOCK_SIZE_0)
    _launcher(_helion_kernel_fixed_block_size, (triton.cdiv(64, _BLOCK_SIZE_1),), loss_sum, y_true, kl_loss, loss, loss_sum.stride(0), _BLOCK_SIZE_1, _RDIM_SIZE_2, _RDIM_SIZE_3, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return torch.sum(loss) / BT
    return torch.sum(loss) / BT

--- assertExpectedJournal(TestLoops.test_reorder_with_register_block_size)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(x, out, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    num_blocks_0 = tl.cdiv(2048, _BLOCK_SIZE_1)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_1 = pid_0 * _BLOCK_SIZE_1
    offset_0 = pid_1 * _BLOCK_SIZE_0
    # src[test_loops.py:N]: out[tile0, tile1] = x[tile0, tile1] + 1
    load = tl.load(tl.make_block_ptr(x, [2048, 2048], [2048, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), boundary_check=[0, 1], padding_option='zero')
    v_0 = 1.0
    v_1 = load + v_0
    tl.store(tl.make_block_ptr(out, [2048, 2048], [2048, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), v_1, boundary_check=[0, 1])

def fn(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    _BLOCK_SIZE_1 = 32
    _BLOCK_SIZE_0 = 64
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    # src[test_loops.py:N]:     out[tile0, tile1] = x[tile0, tile1] + 1
    _launcher(_helion_fn, (triton.cdiv(2048, _BLOCK_SIZE_1) * triton.cdiv(2048, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_1, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_three_level_matmul)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_matmul(x, y, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    # src[test_loops.py:N]: for tile_m in hl.tile(m):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_loops.py:N]: for tile_n in hl.tile(n):
    # src[test_loops.py:N]:     acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_loops.py:N]:     for tile_k in hl.tile(k):
    # src[test_loops.py:N-N]: ...
    for offset_1 in tl.range(0, 128, _BLOCK_SIZE_1):
        indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        # src[test_loops.py:N]: acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
        acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
        # src[test_loops.py:N]: for tile_k in hl.tile(k):
        # src[test_loops.py:N]:     acc = torch.addmm(acc, x[tile_m, tile_k], y[tile_k, tile_n])
        for offset_2 in tl.range(0, 512, _BLOCK_SIZE_2):
            indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
            acc_copy = acc
            acc_copy_0 = acc_copy
            # src[test_loops.py:N]: acc = torch.addmm(acc, x[tile_m, tile_k], y[tile_k, tile_n])
            load = tl.load(x + (indices_0[:, None] * 512 + indices_2[None, :] * 1), None)
            load_1 = tl.load(y + (indices_2[:, None] * 128 + indices_1[None, :] * 1), None)
            acc = tl.dot(tl.cast(load, tl.float32), tl.cast(load_1, tl.float32), acc=acc_copy_0, input_precision='tf32', out_dtype=tl.float32)
        # src[test_loops.py:N]: out[tile_m, tile_n] = acc
        tl.store(out + (indices_0[:, None] * 128 + indices_1[None, :] * 1), acc, None)

def matmul(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: m, k = x.size()
    m, k = x.size()
    # src[test_loops.py:N]: k2, n = y.size()
    k2, n = y.size()
    # src[test_loops.py:N]: assert k == k2, f"size mismatch {k} != {k2}"
    assert k == k2, f'size mismatch {k} != {k2}'
    # src[test_loops.py:N]: out = torch.empty(
    # src[test_loops.py:N]:     [m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device
    # src[test_loops.py:N]: )
    out = torch.empty([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    # src[test_loops.py:N]: for tile_m in hl.tile(m):
    _BLOCK_SIZE_0 = 16
    # src[test_loops.py:N]: for tile_n in hl.tile(n):
    # src[test_loops.py:N]:     acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_loops.py:N]:     for tile_k in hl.tile(k):
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_1 = 64
    # src[test_loops.py:N]: for tile_k in hl.tile(k):
    # src[test_loops.py:N]:     acc = torch.addmm(acc, x[tile_m, tile_k], y[tile_k, tile_n])
    _BLOCK_SIZE_2 = 64
    # src[test_loops.py:N]: for tile_m in hl.tile(m):
    # src[test_loops.py:N]:     for tile_n in hl.tile(n):
    # src[test_loops.py:N]:         acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_matmul, (triton.cdiv(256, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_three_pass_kernel)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_three_pass_kernel(x, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    # src[test_loops.py:N]: for tile_b in hl.tile(B):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_loops.py:N]: sum_val = hl.zeros([tile_b], dtype=torch.float32)
    sum_val = tl.full([_BLOCK_SIZE_0], 0.0, tl.float32)
    # src[test_loops.py:N]: for tile_m in hl.tile(M):
    # src[test_loops.py:N]:     sum_val = sum_val + x[tile_b, tile_m].to(torch.float32).sum(dim=1)
    for offset_1 in tl.range(0, 16, _BLOCK_SIZE_1):
        indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        sum_val_copy = sum_val
        sum_val_copy_0 = sum_val_copy
        # src[test_loops.py:N]: sum_val = sum_val + x[tile_b, tile_m].to(torch.float32).sum(dim=1)
        load = tl.load(x + (indices_0[:, None] * 16 + indices_1[None, :] * 1), None)
        sum_1 = tl.cast(tl.sum(load, 1), tl.float32)
        sum_val = sum_val_copy_0 + sum_1
    # src[test_loops.py:N]: sum_sq = hl.zeros([tile_b], dtype=torch.float32)
    sum_sq = tl.full([_BLOCK_SIZE_0], 0.0, tl.float32)
    # src[test_loops.py:N]: for tile_m in hl.tile(M):
    # src[test_loops.py:N]:     vals = x[tile_b, tile_m].to(torch.float32)
    # src[test_loops.py:N]:     sum_sq = sum_sq + (vals * vals).sum(dim=1)
    for offset_2 in tl.range(0, 16, _BLOCK_SIZE_2):
        indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
        sum_sq_copy = sum_sq
        sum_sq_copy_0 = sum_sq_copy
        # src[test_loops.py:N]: vals = x[tile_b, tile_m].to(torch.float32)
        vals = tl.load(x + (indices_0[:, None] * 16 + indices_2[None, :] * 1), None)
        # src[test_loops.py:N]: sum_sq = sum_sq + (vals * vals).sum(dim=1)
        v_1 = vals * vals
        sum_2 = tl.cast(tl.sum(v_1, 1), tl.float32)
        sum_sq = sum_sq_copy_0 + sum_2
    # src[test_loops.py:N]: mean = sum_val / M
    v_3 = 0.0625
    v_4 = sum_val * v_3
    # src[test_loops.py:N]: var = sum_sq / M - mean * mean
    v_5 = 0.0625
    v_6 = sum_sq * v_5
    v_7 = v_4 * v_4
    v_8 = v_6 - v_7
    # src[test_loops.py:N]: std = torch.sqrt(var + 1e-6)
    v_9 = 1e-06
    v_10 = v_8 + v_9
    v_11 = tl.sqrt_rn(v_10)
    # src[test_loops.py:N]: for tile_m in hl.tile(M):
    # src[test_loops.py:N]:     vals = x[tile_b, tile_m].to(torch.float32)
    # src[test_loops.py:N]:     # Error likely here - mean and std might not be accessible
    # src[test_loops.py:N-N]: ...
    for offset_3 in tl.range(0, 16, _BLOCK_SIZE_3):
        indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
        v_4_copy = v_4
        v_11_copy = v_11
        v_4_copy_0 = v_4_copy
        v_11_copy_0 = v_11_copy
        # src[test_loops.py:N]: vals = x[tile_b, tile_m].to(torch.float32)
        vals_1 = tl.load(x + (indices_0[:, None] * 16 + indices_3[None, :] * 1), None)
        # src[test_loops.py:N]: normalized = (vals - mean[:, None]) / std[:, None]
        subscript = v_4_copy_0[:, None]
        v_12 = vals_1 - subscript
        subscript_1 = v_11_copy_0[:, None]
        v_13 = v_12 / subscript_1
        # src[test_loops.py:N]: out[tile_b, tile_m] = normalized.to(x.dtype)
        tl.store(out + (indices_0[:, None] * 16 + indices_3[None, :] * 1), v_13, None)

def three_pass_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: B, M = x.size()
    B, M = x.size()
    # src[test_loops.py:N]: out = torch.zeros_like(x)
    out = torch.zeros_like(x)
    # src[test_loops.py:N]: for tile_b in hl.tile(B):
    _BLOCK_SIZE_0 = 2
    # src[test_loops.py:N]: for tile_m in hl.tile(M):
    # src[test_loops.py:N]:     sum_val = sum_val + x[tile_b, tile_m].to(torch.float32).sum(dim=1)
    _BLOCK_SIZE_1 = 8
    # src[test_loops.py:N]: for tile_m in hl.tile(M):
    # src[test_loops.py:N]:     vals = x[tile_b, tile_m].to(torch.float32)
    # src[test_loops.py:N]:     sum_sq = sum_sq + (vals * vals).sum(dim=1)
    _BLOCK_SIZE_2 = 8
    # src[test_loops.py:N]: for tile_m in hl.tile(M):
    # src[test_loops.py:N]:     vals = x[tile_b, tile_m].to(torch.float32)
    # src[test_loops.py:N]:     # Error likely here - mean and std might not be accessible
    # src[test_loops.py:N-N]: ...
    _BLOCK_SIZE_3 = 8
    # src[test_loops.py:N]: for tile_b in hl.tile(B):
    # src[test_loops.py:N]:     # Pass 1: Compute sum
    # src[test_loops.py:N]:     sum_val = hl.zeros([tile_b], dtype=torch.float32)
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_three_pass_kernel, (triton.cdiv(4, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_unroll_with_pipelining)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_matmul(x, y, out, _NUM_SM: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    # src[test_loops.py:N]: for tile_m, tile_n in hl.tile([m, n]):
    # src[test_loops.py:N]:     acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_loops.py:N]:     for tile_k in hl.tile(k):
    # src[test_loops.py:N-N]: ...
    total_pids = tl.cdiv(256, _BLOCK_SIZE_1) * tl.cdiv(256, _BLOCK_SIZE_0)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid, loop_unroll_factor=4, num_stages=1):
        # src[test_loops.py:N]: for tile_m, tile_n in hl.tile([m, n]):
        num_blocks_0 = tl.cdiv(256, _BLOCK_SIZE_1)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_1 = pid_0 * _BLOCK_SIZE_1
        offset_0 = pid_1 * _BLOCK_SIZE_0
        # src[test_loops.py:N]: acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
        acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
        # src[test_loops.py:N]: for tile_k in hl.tile(k):
        # src[test_loops.py:N]:     acc = torch.addmm(acc, x[tile_m, tile_k], y[tile_k, tile_n])
        for offset_2 in tl.range(0, 256, _BLOCK_SIZE_2, loop_unroll_factor=4, num_stages=1):
            acc_copy = acc
            acc_copy_0 = acc_copy
            # src[test_loops.py:N]: acc = torch.addmm(acc, x[tile_m, tile_k], y[tile_k, tile_n])
            load = tl.load(tl.make_block_ptr(x, [256, 256], [256, 1], [offset_0, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_2], [1, 0]), boundary_check=[0, 1], padding_option='zero')
            load_1 = tl.load(tl.make_block_ptr(y, [256, 256], [256, 1], [offset_2, offset_1], [_BLOCK_SIZE_2, _BLOCK_SIZE_1], [1, 0]), boundary_check=[0, 1], padding_option='zero')
            acc = tl.dot(tl.cast(load, tl.bfloat16), tl.cast(load_1, tl.bfloat16), acc=acc_copy_0, input_precision='tf32', out_dtype=tl.float32)
        # src[test_loops.py:N]: out[tile_m, tile_n] = acc
        v_0 = tl.cast(acc, tl.bfloat16)
        tl.store(tl.make_block_ptr(out, [256, 256], [256, 1], [offset_0, offset_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1], [1, 0]), v_0, boundary_check=[0, 1])

def matmul(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_loops.py:N]: m, k = x.size()
    m, k = x.size()
    # src[test_loops.py:N]: k2, n = y.size()
    k2, n = y.size()
    # src[test_loops.py:N]: assert k == k2, f"size mismatch {k} != {k2}"
    assert k == k2, f'size mismatch {k} != {k2}'
    # src[test_loops.py:N]: out = torch.empty(
    # src[test_loops.py:N]:     [m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device
    # src[test_loops.py:N]: )
    out = torch.empty([m, n], dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    # src[test_loops.py:N]: for tile_m, tile_n in hl.tile([m, n]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_1 = 16
    _BLOCK_SIZE_0 = 64
    # src[test_loops.py:N]: for tile_k in hl.tile(k):
    # src[test_loops.py:N]:     acc = torch.addmm(acc, x[tile_m, tile_k], y[tile_k, tile_n])
    _BLOCK_SIZE_2 = 16
    # src[test_loops.py:N]: for tile_m, tile_n in hl.tile([m, n]):
    # src[test_loops.py:N]:     acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_loops.py:N]:     for tile_k in hl.tile(k):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_matmul, (_NUM_SM,), x, y, out, _NUM_SM, _BLOCK_SIZE_1, _BLOCK_SIZE_0, _BLOCK_SIZE_2, num_warps=4, num_stages=1)
    # src[test_loops.py:N]: return out
    return out
