This file is automatically generated by assertExpectedJournal calls in test_triton_kernel.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestTritonKernel.test_triton_kernel_function_object)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_triton_kernel as _source_module

@triton.jit
def add_pairs(a, b):
    # src[test_triton_kernel.py:N]: def k(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
    return a + b

@triton.jit
def _helion_k(x, y, out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_triton_kernel.py:N]: x_val = x[tile]
    x_val = tl.load(x + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: y_val = y[tile]
    y_val = tl.load(y + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: result = hl.triton_kernel(
    # src[test_triton_kernel.py:N]:     add_pairs, args=(x_val, y_val), output_like=x_val
    # src[test_triton_kernel.py:N]: )
    triton_kernel_result = add_pairs(x_val, y_val)
    tl.static_assert(triton_kernel_result.dtype == tl.float32, 'inline_triton output dtype mismatch; expected torch.float32')
    tl.static_assert(triton_kernel_result.shape == x_val.shape, 'inline_triton output shape mismatch')
    # src[test_triton_kernel.py:N]: out[tile] = result
    tl.store(out + indices_0 * 1, triton_kernel_result, None)

def k(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_triton_kernel.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    _BLOCK_SIZE_0 = 32
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    # src[test_triton_kernel.py:N]:     x_val = x[tile]
    # src[test_triton_kernel.py:N]:     y_val = y[tile]
    # src[test_triton_kernel.py:N-N]: ...
    _launcher(_helion_k, (triton.cdiv(128, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_triton_kernel.py:N]: return out
    return out

--- assertExpectedJournal(TestTritonKernel.test_triton_kernel_function_object_with_helpers)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_triton_kernel as _source_module

@triton.jit
def nested_helper_calls(a):
    # src[test_triton_kernel.py:N]: def k(x: torch.Tensor) -> torch.Tensor:
    return _helper_process(a)

@triton.jit
def _helper_process(x):
    # src[test_triton_kernel.py:N]: # Pass function object directly
    doubled = _helper_double(x)
    # src[test_triton_kernel.py:N]: out[tile] = hl.triton_kernel(
    return _helper_add_one(doubled)

@triton.jit
def _helper_double(x):
    # src[test_triton_kernel.py:N]: )
    return x * 2.0

@triton.jit
def _helper_add_one(x):
    # src[test_triton_kernel.py:N]: code, result = code_and_output(k, (x,))
    return x + 1.0

@triton.jit
def _helion_k(x, out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_triton_kernel.py:N]: x_val = x[tile]
    x_val = tl.load(x + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: out[tile] = hl.triton_kernel(
    # src[test_triton_kernel.py:N]:     nested_helper_calls,
    # src[test_triton_kernel.py:N]:     args=(x_val,),
    # src[test_triton_kernel.py:N-N]: ...
    triton_kernel_result = nested_helper_calls(x_val)
    tl.static_assert(triton_kernel_result.dtype == tl.float32, 'inline_triton output dtype mismatch; expected torch.float32')
    tl.static_assert(triton_kernel_result.shape == x_val.shape, 'inline_triton output shape mismatch')
    tl.store(out + indices_0 * 1, triton_kernel_result, None)

def k(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_triton_kernel.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    _BLOCK_SIZE_0 = 32
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    # src[test_triton_kernel.py:N]:     x_val = x[tile]
    # src[test_triton_kernel.py:N]:     # Pass function object directly
    # src[test_triton_kernel.py:N-N]: ...
    _launcher(_helion_k, (triton.cdiv(128, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_triton_kernel.py:N]: return out
    return out

--- assertExpectedJournal(TestTritonKernel.test_triton_kernel_multi_output)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_triton_kernel as _source_module

@triton.jit
def pairwise_ops(a, b):
    # src[test_triton_kernel.py:N]: def k(x: torch.Tensor, y: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
    sum_val = a + b
    # src[test_triton_kernel.py:N]: sum_out = torch.empty_like(x)
    prod_val = a * b
    # src[test_triton_kernel.py:N]: prod_out = torch.empty_like(x)
    return (sum_val, prod_val)

@triton.jit
def _helion_k(x, y, sum_out, prod_out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_triton_kernel.py:N]: x_val = x[tile]
    x_val = tl.load(x + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: y_val = y[tile]
    y_val = tl.load(y + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: sum_val, prod_val = hl.triton_kernel(
    # src[test_triton_kernel.py:N]:     "pairwise_ops",
    # src[test_triton_kernel.py:N]:     args=(x_val, y_val),
    # src[test_triton_kernel.py:N-N]: ...
    triton_kernel_result = pairwise_ops(x_val, y_val)
    tl.static_assert(len(triton_kernel_result) == 2, 'inline_triton expected 2 outputs')
    tl.static_assert(triton_kernel_result[0].dtype == tl.float32, 'inline_triton output 0 dtype mismatch; expected torch.float32')
    tl.static_assert(triton_kernel_result[0].shape == x_val.shape, 'inline_triton output 0 shape mismatch')
    tl.static_assert(triton_kernel_result[1].dtype == tl.float32, 'inline_triton output 1 dtype mismatch; expected torch.float32')
    tl.static_assert(triton_kernel_result[1].shape == x_val.shape, 'inline_triton output 1 shape mismatch')
    sum_val = triton_kernel_result[0]
    prod_val = triton_kernel_result[1]
    # src[test_triton_kernel.py:N]: sum_out[tile] = sum_val
    tl.store(sum_out + indices_0 * 1, sum_val, None)
    # src[test_triton_kernel.py:N]: prod_out[tile] = prod_val
    tl.store(prod_out + indices_0 * 1, prod_val, None)

def k(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_triton_kernel.py:N]: sum_out = torch.empty_like(x)
    sum_out = torch.empty_like(x)
    # src[test_triton_kernel.py:N]: prod_out = torch.empty_like(x)
    prod_out = torch.empty_like(x)
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    _BLOCK_SIZE_0 = 32
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    # src[test_triton_kernel.py:N]:     x_val = x[tile]
    # src[test_triton_kernel.py:N]:     y_val = y[tile]
    # src[test_triton_kernel.py:N-N]: ...
    _launcher(_helion_k, (triton.cdiv(64, _BLOCK_SIZE_0),), x, y, sum_out, prod_out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_triton_kernel.py:N]: return sum_out, prod_out
    return (sum_out, prod_out)

--- assertExpectedJournal(TestTritonKernel.test_triton_kernel_output_like_none)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_triton_kernel as _source_module

@triton.jit
def side_effect_noop(x):
    # src[test_triton_kernel.py:N]: out = torch.empty_like(x)
    tl.debug_barrier()

@triton.jit
def _helion_k(x, out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_triton_kernel.py:N]: x_val = x[tile]
    x_val = tl.load(x + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: hl.triton_kernel(
    # src[test_triton_kernel.py:N]:     "side_effect_noop",
    # src[test_triton_kernel.py:N]:     args=(x_val,),
    # src[test_triton_kernel.py:N-N]: ...
    side_effect_noop(x_val)
    # src[test_triton_kernel.py:N]: out[tile] = x_val
    tl.store(out + indices_0 * 1, x_val, None)

def k(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_triton_kernel.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    _BLOCK_SIZE_0 = 32
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    # src[test_triton_kernel.py:N]:     x_val = x[tile]
    # src[test_triton_kernel.py:N]:     # Call triton_kernel with output_like=None (side-effect only)
    # src[test_triton_kernel.py:N-N]: ...
    _launcher(_helion_k, (triton.cdiv(128, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_triton_kernel.py:N]: return out
    return out

--- assertExpectedJournal(TestTritonKernel.test_triton_kernel_simple_add)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_triton_kernel as _source_module

@triton.jit
def add_pairs(a, b):
    # src[test_triton_kernel.py:N]: def triton_kernel_add_pairs(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
    return a + b

@triton.jit
def _helion_triton_kernel_add_pairs(x, y, out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_triton_kernel.py:N]: x_val = x[tile]
    x_val = tl.load(x + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: y_val = y[tile]
    y_val = tl.load(y + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: result = hl.triton_kernel("add_pairs", args=(x_val, y_val), output_like=x_val)
    triton_kernel_result = add_pairs(x_val, y_val)
    tl.static_assert(triton_kernel_result.dtype == tl.float32, 'inline_triton output dtype mismatch; expected torch.float32')
    tl.static_assert(triton_kernel_result.shape == x_val.shape, 'inline_triton output shape mismatch')
    # src[test_triton_kernel.py:N]: out[tile] = result
    tl.store(out + indices_0 * 1, triton_kernel_result, None)

def triton_kernel_add_pairs(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_triton_kernel.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    _BLOCK_SIZE_0 = 32
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    # src[test_triton_kernel.py:N]:     x_val = x[tile]
    # src[test_triton_kernel.py:N]:     y_val = y[tile]
    # src[test_triton_kernel.py:N-N]: ...
    _launcher(_helion_triton_kernel_add_pairs, (triton.cdiv(128, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_triton_kernel.py:N]: return out
    return out

--- assertExpectedJournal(TestTritonKernel.test_triton_kernel_tl_ops)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_triton_kernel as _source_module

@triton.jit
def vector_mix_norm(a, b):
    # src[test_triton_kernel.py:N]: def k(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
    mixed = tl.where(a > b, a - b, a + b)
    # src[test_triton_kernel.py:N]: out = torch.empty_like(x)
    l2sq = tl.sum(mixed * mixed)
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    inv = tl.rsqrt(tl.maximum(l2sq, 1e-12))
    # src[test_triton_kernel.py:N]: x_val = x[tile]
    return mixed * inv

@triton.jit
def _helion_k(x, y, out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_triton_kernel.py:N]: x_val = x[tile]
    x_val = tl.load(x + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: y_val = y[tile]
    y_val = tl.load(y + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: out[tile] = hl.triton_kernel(
    # src[test_triton_kernel.py:N]:     "vector_mix_norm",
    # src[test_triton_kernel.py:N]:     args=(x_val, y_val),
    # src[test_triton_kernel.py:N-N]: ...
    triton_kernel_result = vector_mix_norm(x_val, y_val)
    tl.static_assert(triton_kernel_result.dtype == tl.float32, 'inline_triton output dtype mismatch; expected torch.float32')
    tl.static_assert(triton_kernel_result.shape == x_val.shape, 'inline_triton output shape mismatch')
    tl.store(out + indices_0 * 1, triton_kernel_result, None)

def k(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_triton_kernel.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    _BLOCK_SIZE_0 = 32
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    # src[test_triton_kernel.py:N]:     x_val = x[tile]
    # src[test_triton_kernel.py:N]:     y_val = y[tile]
    # src[test_triton_kernel.py:N-N]: ...
    _launcher(_helion_k, (triton.cdiv(96, _BLOCK_SIZE_0),), x, y, out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_triton_kernel.py:N]: return out
    return out

--- assertExpectedJournal(TestTritonKernel.test_triton_kernel_with_multiple_globals)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_triton_kernel as _source_module
# src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
GLOBAL_SCALE_FACTOR = tl.constexpr(2.0)
# src[test_triton_kernel.py:N]: out[tile] = hl.triton_kernel(
GLOBAL_EPSILON = tl.constexpr(1e-06)

@triton.jit
def normalize_with_globals(a):
    # src[test_triton_kernel.py:N]: def k(x: torch.Tensor) -> torch.Tensor:
    return a * GLOBAL_SCALE_FACTOR + GLOBAL_EPSILON

@triton.jit
def _helion_k(x, out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_triton_kernel.py:N]: x_val = x[tile]
    x_val = tl.load(x + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: out[tile] = hl.triton_kernel(
    # src[test_triton_kernel.py:N]:     "normalize_with_globals",
    # src[test_triton_kernel.py:N]:     args=(x_val,),
    # src[test_triton_kernel.py:N-N]: ...
    triton_kernel_result = normalize_with_globals(x_val)
    tl.static_assert(triton_kernel_result.dtype == tl.float32, 'inline_triton output dtype mismatch; expected torch.float32')
    tl.static_assert(triton_kernel_result.shape == x_val.shape, 'inline_triton output shape mismatch')
    tl.store(out + indices_0 * 1, triton_kernel_result, None)

def k(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_triton_kernel.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    _BLOCK_SIZE_0 = 32
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    # src[test_triton_kernel.py:N]:     x_val = x[tile]
    # src[test_triton_kernel.py:N]:     out[tile] = hl.triton_kernel(
    # src[test_triton_kernel.py:N-N]: ...
    _launcher(_helion_k, (triton.cdiv(128, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_triton_kernel.py:N]: return out
    return out

--- assertExpectedJournal(TestTritonKernel.test_triton_kernel_with_nested_helpers)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_triton_kernel as _source_module

@triton.jit
def nested_helper_calls(a):
    # src[test_triton_kernel.py:N]: def k(x: torch.Tensor) -> torch.Tensor:
    return _helper_process(a)

@triton.jit
def _helper_process(x):
    # src[test_triton_kernel.py:N]: out[tile] = hl.triton_kernel(
    doubled = _helper_double(x)
    # src[test_triton_kernel.py:N]: "nested_helper_calls",
    return _helper_add_one(doubled)

@triton.jit
def _helper_double(x):
    # src[test_triton_kernel.py:N]: return out
    return x * 2.0

@triton.jit
def _helper_add_one(x):
    # src[test_triton_kernel.py:N]: # Verify all nested helper functions are copied
    return x + 1.0

@triton.jit
def _helion_k(x, out, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_triton_kernel.py:N]: x_val = x[tile]
    x_val = tl.load(x + indices_0 * 1, None)
    # src[test_triton_kernel.py:N]: out[tile] = hl.triton_kernel(
    # src[test_triton_kernel.py:N]:     "nested_helper_calls",
    # src[test_triton_kernel.py:N]:     args=(x_val,),
    # src[test_triton_kernel.py:N-N]: ...
    triton_kernel_result = nested_helper_calls(x_val)
    tl.static_assert(triton_kernel_result.dtype == tl.float32, 'inline_triton output dtype mismatch; expected torch.float32')
    tl.static_assert(triton_kernel_result.shape == x_val.shape, 'inline_triton output shape mismatch')
    tl.store(out + indices_0 * 1, triton_kernel_result, None)

def k(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_triton_kernel.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    _BLOCK_SIZE_0 = 32
    # src[test_triton_kernel.py:N]: for tile in hl.tile(x.shape):
    # src[test_triton_kernel.py:N]:     x_val = x[tile]
    # src[test_triton_kernel.py:N]:     out[tile] = hl.triton_kernel(
    # src[test_triton_kernel.py:N-N]: ...
    _launcher(_helion_k, (triton.cdiv(128, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_triton_kernel.py:N]: return out
    return out
